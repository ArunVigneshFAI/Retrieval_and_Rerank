{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sys\n",
    "import config\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import gzip\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Import OpenAI and other necessary modules\n",
    "import openai\n",
    "\n",
    "# Import classes and functions from modules\n",
    "from llama_index import (\n",
    "    Document,\n",
    "    VectorStoreIndex,\n",
    "    ListIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    SimpleKeywordTableIndex,\n",
    ")\n",
    "from llama_index.indices.postprocessor import (\n",
    "    LLMRerank\n",
    ")\n",
    "from llama_index.response.notebook_utils import display_response\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().handlers = []\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenAI API Key Authentication (The OpenAI API Key will be stored in the config.py file)\n",
    "openai.api_key = config.openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI's LLM (Language Learning Model)\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "service_context = ServiceContext.from_defaults(chunk_size=1024, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and process query, document, and relevance data\n",
    "df_queries = pd.read_csv('antique_query_test.csv')\n",
    "df_queries = df_queries[['query_id','text']]\n",
    "\n",
    "df_docs = pd.read_csv('antique_sample_404k.csv')\n",
    "df_docs = df_docs[['doc_id','text']]\n",
    "\n",
    "df_qrel = pd.read_csv('antique_qurel_test.csv')\n",
    "df_qrel = df_qrel[['query_id','doc_id','relevance']]\n",
    "\n",
    "# Merge relevant data for query and document\n",
    "merged_df = df_qrel.merge(df_docs, on='doc_id', how='left')\n",
    "\n",
    "# Extract text data from merged DataFrame\n",
    "df_text = merged_df[['doc_id','text']]\n",
    "\n",
    "# Initialize an empty list to store passages\n",
    "passages = []\n",
    "\n",
    "# Iterate through each row in the 'df_text' DataFrame and append text to the 'passages' list\n",
    "for index, row in df_text.iterrows():\n",
    "    passages.append(str(row['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-computed document embeddings\n",
    "import pickle\n",
    "with open('corpus_embeddings_text.pickle', 'rb') as pkl:\n",
    "    doc_embedding = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained SentenceTransformer: intfloat/e5-base-v2\n",
      "Created a temporary directory at /var/folders/75/0dtb1gc52pdfr40bnpp97qj00000gn/T/tmpyns87k4m\n",
      "Writing /var/folders/75/0dtb1gc52pdfr40bnpp97qj00000gn/T/tmpyns87k4m/_remote_module_non_scriptable.py\n",
      "Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Initialize SentenceTransformer for embedding\n",
    "bi_encoder = SentenceTransformer('intfloat/e5-base-v2')\n",
    "bi_encoder.max_seq_length = 256     #Truncate long passages to 256 tokens\n",
    "# top_k = 32                          #Number of passages we want to retrieve with the bi-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform semantic search\n",
    "\n",
    "# This function will search all the articles for passages that\n",
    "# answer the query\n",
    "def search(input_query):  \n",
    "    output_answers=[]  \n",
    "    ##### Sematic Search #####\n",
    "    # Encode the query using the bi-encoder and find potentially relevant passages\n",
    "    question_embedding = bi_encoder.encode(input_query, convert_to_tensor=True)\n",
    "    hits = util.semantic_search(question_embedding, doc_embedding, top_k=10)\n",
    "    hits = hits[0]  # Get the hits for the first query\n",
    "\n",
    "    hits = sorted(hits, key=lambda x: x['score'], reverse=True)\n",
    "    for hit in hits:\n",
    "        output_answer =  passages[hit['corpus_id']].replace(\"\\n\", \" \")\n",
    "        output_answers.append(output_answer)  # Append to the list\n",
    "\n",
    "    return output_answers  # Return the list of output answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform LLM Reranking\n",
    "\n",
    "def rerank__query_engine(question, retrieved_docs):\n",
    "    # Create Document objects for the retrieved documents\n",
    "    documents = [Document(text=t) for t in retrieved_docs]\n",
    "\n",
    "    # Create a VectorStoreIndex from the retrieved documents\n",
    "    retrieved_docs_index = VectorStoreIndex.from_documents(documents)\n",
    "    \n",
    "    # Initialize an LLM reranker\n",
    "    reranker = LLMRerank(top_n=10)\n",
    "\n",
    "    # Create a query engine with reranking  \n",
    "    query_engine = retrieved_docs_index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    node_postprocessors=[reranker],\n",
    "    )\n",
    "\n",
    "    # Query the engine\n",
    "    response = query_engine.query(question)\n",
    "    \n",
    "    display_response(\n",
    "        response, show_source=True, source_length=500\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    # Perform semantic search on a sample query\n",
    "    retrieved_docs = search(input_query = question)\n",
    "    # Perform LLM rerank \n",
    "    rerank__query_engine(question = question, retrieved_docs=retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b75c2e40714f85abff16f5e805d239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** To find out if a watermelon is ripe, you can check for a few signs. Look for a yellow spot on the underside of the watermelon, which indicates where the watermelon has been resting on the ground. The spot should be creamy yellow, not white. You can also thump the watermelon and listen for a deep hollow sound, which indicates that the watermelon is ripe. Finally, you can lift the watermelon and check for its weight. A ripe watermelon should feel heavy for its size."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 1/2`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 4f5341c9-6fbe-40fb-b5d7-ede8f948bed2<br>**Similarity:** 3.0<br>**Text:** You can bake them, just like a regular baked potato. Peirce the skin with a fork to let steam escape...They take a little longer than a reg pot, I think cause theyre denser?. You can eat them with brown sugar, cinemon & butter....<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 2/2`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 9393a5cc-b916-430b-b27d-b43acb716260<br>**Similarity:** 2.0<br>**Text:** leave the skins on and cut into cubes. then drizzle with olive oil or butter, dried herbs & salt. bake until skin flesh browns. Also makes good garlic mashed potatoes....<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask_question(question = \"How to find out if a watermelon is ripe?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
